{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B.C. Classification",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhayMudgal/Breast_Cancer_Detection/blob/main/B_C_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roDmtgNYvfFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64cd80a-24f6-44f6-99c6-8f0c9ff4dea0"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VerbeioevnRR"
      },
      "source": [
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from shutil import copyfile\n",
        "from os import makedirs, listdir\n",
        "import cv2\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BH4zSD5v5aw"
      },
      "source": [
        "kaggle_json = {\"username\":\"abhay1010\",\"key\":\"4af3df22394b3bfc76ea750845f8b173\"}\n",
        "makedirs(\"/content/.kaggle/\", exist_ok = True)\n",
        "makedirs(\"/root/.kaggle/\", exist_ok = True)\n",
        "with open(\"/content/.kaggle/kaggle.json\", 'w') as file:\n",
        "  json.dump(kaggle_json, file)\n",
        "\n",
        "!cp \"/content/.kaggle/kaggle.json\" \"/root/.kaggle/kaggle.json\"\n",
        "!chmod 600 \"/content/.kaggle/kaggle.json\"\n",
        "!chmod 600 \"/root/.kaggle/kaggle.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trrFBJumwuXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88322f8-677d-4ff0-f958-ad8a7ab0a86d"
      },
      "source": [
        "%ls \"/content/.kaggle/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4SSgCgzwyut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e31a1c-ecd6-4857-9991-54e90da3c046"
      },
      "source": [
        "! kaggle datasets list -s Histopathology"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                            title                                             size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  \n",
            "paultimothymooney/breast-histopathology-images                 Breast Histopathology Images                       3GB  2017-12-19 05:46:40          27156  \n",
            "andrewmvd/lung-and-colon-cancer-histopathological-images       Lung and Colon Cancer Histopathological Images     2GB  2020-04-14 06:57:56           1598  \n",
            "forderation/breakhis-400x                                      BreaKHis 400X                                    803MB  2020-07-29 03:58:30            744  \n",
            "kmader/skin-cancer-mnist-ham10000                              Skin Cancer MNIST: HAM10000                        5GB  2018-09-20 20:36:13          42983  \n",
            "linjustin/train-val-test-tcga-coad-msi-mss                     Gastrointestinal Cancer MSI MSS Prediction         5GB  2020-04-09 22:40:44            514  \n",
            "drscarlat/melanoma                                             melanoma                                           5GB  2018-12-02 04:01:51           2253  \n",
            "adacslicml/breast-histopathology-images                        Breast Histopathology Images                     159MB  2021-02-12 09:10:29             52  \n",
            "ambarish/kimia-path-960                                        KIMIA_Path_960                                   247MB  2019-05-23 11:22:00            114  \n",
            "andrewmvd/breast-cancer-cell-segmentation                      Breast Cancer Cell Segmentation                   94MB  2020-04-19 21:12:49            812  \n",
            "discdiver/mnist1000-with-one-image-folder                      MNIST1000_with_one_image_folder                    5GB  2019-03-20 17:30:54            563  \n",
            "aicoder/histopathology-dataset                                 histopathology dataset                             2GB  2021-03-07 05:39:16             30  \n",
            "shirishsharma/transfer-learning-on-breast-histopathology-data  transfer learning on breast histopathology data    5GB  2021-01-02 05:36:04             16  \n",
            "tywangty/histopathologiccancerwsi                              histopathologic-cancer-WSI                         5MB  2019-03-14 13:21:16            154  \n",
            "dinhanhx/skin-cancer-mnist-ham10000                            Skin Cancer MNIST: HAM10000                       25MB  2020-11-21 10:54:39             60  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6xHH8STxhig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc799a8d-f3b4-4561-cb2d-8ff0558529ae"
      },
      "source": [
        "! kaggle datasets download -d paultimothymooney/breast-histopathology-images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading breast-histopathology-images.zip to /content\n",
            "100% 3.09G/3.10G [00:50<00:00, 57.3MB/s]\n",
            "100% 3.10G/3.10G [00:51<00:00, 65.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tehsg5WOv1kC"
      },
      "source": [
        "! unzip /content/breast-histopathology-images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDhvqkB4zUGC"
      },
      "source": [
        "size = 50\n",
        "val_split = 0.1\n",
        "Batch_size = 64\n",
        "lr = 0.001\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUyYqKT2xm3e"
      },
      "source": [
        "test = []\n",
        "train = []\n",
        "test_y = []\n",
        "train_y = []\n",
        "for files in listdir(\"/content/IDC_regular_ps50_idx5\"):\n",
        "  path = \"/content/IDC_regular_ps50_idx5/\" + files\n",
        "  for types in listdir(path):\n",
        "    label = int (types)\n",
        "    dir = \"/content/IDC_regular_ps50_idx5/\" + files + \"/\" + types\n",
        "    for sample in listdir(dir):\n",
        "      image = dir + '/' + sample\n",
        "      img = cv2.imread(image)\n",
        "     \n",
        "      img = cv2.resize(img, (size, size))\n",
        "      \n",
        "      data = np.asarray(img)\n",
        "      \n",
        "      if random.random()<val_split:\n",
        "        test.append(data)\n",
        "        test_y.append(label)\n",
        "      else:\n",
        "        train.append(data)  \n",
        "        train_y.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxByPNrWxuRy"
      },
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as k\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_14A6vxsyw8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58cc45f5-8bc7-4c0e-daa7-12332c395621"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(train, train_y, test_size = 0.15, random_state = 1)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "\n",
        "print(X_train.shape, X_val.shape)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale = 1/255.0, width_shift_range=0.1, height_shift_range = 0.1, zoom_range = 0.1, shear_range = 0.1, fill_mode = \"nearest\")\n",
        "val_datagen = ImageDataGenerator(rescale = 1/255.0, width_shift_range=0.1, height_shift_range = 0.1, zoom_range = 0.1)\n",
        "\n",
        "train_gen = datagen.flow(X_train, Y_train, batch_size = Batch_size)\n",
        "val_gen = val_datagen.flow(X_val, Y_val, batch_size = Batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(212467, 50, 50, 3) (37495, 50, 50, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8lmYAq200d0"
      },
      "source": [
        "CNN = k.Sequential([\n",
        "  Conv2D(32, (3, 3), activation = 'relu', input_shape = (size, size, 3)),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Dropout(0.2),\n",
        "  Conv2D(64, (3, 3), activation = 'relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Dropout(0.2),\n",
        "  Conv2D(128, (3, 3), activation = 'relu'),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Dropout(0.2),\n",
        "  Flatten(),\n",
        "  Dense(512, activation = 'relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(64, activation = 'relu'),\n",
        "  Dense(1, activation = 'sigmoid')                       \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDi_oIcHAxMY"
      },
      "source": [
        "opt = k.optimizers.Adam(learning_rate=0.01)\n",
        "CNN.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FysaJo4QCQzU"
      },
      "source": [
        "CNN.fit(train_gen, epochs = epochs, validation_data = val_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlz9PkisJWWA"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "pre = VGG16(include_top = False, weights = 'imagenet', input_shape = (size, size, 3))\n",
        "\n",
        "for layer in pre.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = Flatten()(pre.layers[-1].output)\n",
        "x = Dense(512, activation = 'relu')(x)\n",
        "x = Dense(128, activation = 'relu')(x)\n",
        "x = Dense(32, activation = 'relu')(x)\n",
        "output = Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "VGG = keras.Model(pre.inputs, output)\n",
        "\n",
        "VGG.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [accuracy])\n",
        "\n",
        "run = VGG.fit(train_gen, epochs = 15, validation_data = val_gen)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}